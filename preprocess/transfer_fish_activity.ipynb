{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bleaching', 'fishing_activity', 'mmsi-daily-csvs-10-v2-2012', 'mmsi-daily-csvs-10-v2-2013', 'mmsi-daily-csvs-10-v2-2014', 'mmsi-daily-csvs-10-v2-2015', 'mmsi-daily-csvs-10-v2-2016', 'mmsi-daily-csvs-10-v2-2017', 'mmsi-daily-csvs-10-v2-2018', 'mmsi-daily-csvs-10-v2-2019', 'protected_area']\n"
     ]
    }
   ],
   "source": [
    "path_data = os.path.join(os.getcwd(),os.pardir,os.pardir,'data')\n",
    "data_list = os.listdir(path_data)\n",
    "print(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2012\n",
    "filename = 'mmsi-daily-csvs-10-v2-' + str(year)\n",
    "fishing_data_path = os.path.join(path_data,filename)\n",
    "# encoding='ISO-8859-1' for read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "start_date = datetime(year, 1, 1)\n",
    "end_date = datetime(year, 12, 31)\n",
    "delta = timedelta(days=1)\n",
    "\n",
    "aggregated_data = pd.DataFrame()\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    file_name = current_date.strftime('%Y-%m-%d') + '.csv'\n",
    "    file_path = os.path.join(fishing_data_path, file_name)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        daily_data = pd.read_csv(file_path)\n",
    "        daily_data = daily_data[['cell_ll_lat', 'cell_ll_lon', 'fishing_hours']]\n",
    "        daily_data = daily_data[daily_data['fishing_hours'] > 0]\n",
    "        \n",
    "        daily_data = daily_data[\n",
    "            ((daily_data['cell_ll_lat'] >= 0) & (daily_data['cell_ll_lat'] <= 40) &\n",
    "             (daily_data['cell_ll_lon'] >= 100) & (daily_data['cell_ll_lon'] <= 140)) |\n",
    "            ((daily_data['cell_ll_lat'] >= 0) & (daily_data['cell_ll_lat'] <= 40) &\n",
    "             (daily_data['cell_ll_lon'] >= -100) & (daily_data['cell_ll_lon'] <= -60))\n",
    "        ]\n",
    "\n",
    "        if aggregated_data.empty:\n",
    "            aggregated_data = daily_data\n",
    "        else:\n",
    "            aggregated_data = pd.concat([aggregated_data, daily_data])\n",
    "\n",
    "    current_date += delta\n",
    "\n",
    "aggregated_data = aggregated_data.groupby(['cell_ll_lat', 'cell_ll_lon']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# # Define the bin size for latitude and longitude\n",
    "# lat_bin_size = 2\n",
    "# lon_bin_size = 2\n",
    "\n",
    "# def calculate_bin(value, bin_size):\n",
    "#     bin_center = ((value + bin_size/2) // bin_size) * bin_size\n",
    "#     return bin_center\n",
    "\n",
    "# start_date = datetime(year, 1, 1)\n",
    "# end_date = datetime(year, 12, 31)\n",
    "# delta = timedelta(days=1)\n",
    "\n",
    "# # Initialize the aggregated data\n",
    "# aggregated_data = pd.DataFrame()\n",
    "\n",
    "# current_date = start_date\n",
    "# while current_date <= end_date:\n",
    "#     file_name = current_date.strftime('%Y-%m-%d') + '.csv'\n",
    "#     file_path = os.path.join(fishing_data_path, file_name)\n",
    "    \n",
    "#     if os.path.exists(file_path):\n",
    "#         daily_data = pd.read_csv(file_path)\n",
    "#         daily_data = daily_data[['cell_ll_lat', 'cell_ll_lon', 'fishing_hours']]\n",
    "#         daily_data = daily_data[daily_data['fishing_hours'] > 0]\n",
    "\n",
    "#     # Bin the data by rounding down to the nearest multiple of 5 degrees\n",
    "#     # daily_data['lat_bin'] = (daily_data['cell_ll_lat'] // lat_bin_size) * lat_bin_size\n",
    "#     # daily_data['lon_bin'] = (daily_data['cell_ll_lon'] // lon_bin_size) * lon_bin_size\n",
    "#     daily_data['lat_bin'] = daily_data['cell_ll_lat'].apply(calculate_bin, bin_size=lat_bin_size)\n",
    "#     daily_data['lon_bin'] = daily_data['cell_ll_lon'].apply(calculate_bin, bin_size=lon_bin_size)\n",
    "    \n",
    "#     # Group by the binned lat/lon and sum the 'fishing_hours', then compute the mean\n",
    "#     daily_grouped = daily_data.groupby(['lat_bin', 'lon_bin']).agg({'fishing_hours': 'mean'}).reset_index()\n",
    "    \n",
    "#     # Concatenate the grouped data to the aggregated data\n",
    "#     aggregated_data = pd.concat([aggregated_data, daily_grouped])\n",
    "    \n",
    "#     # Increment the date by one day\n",
    "#     current_date += delta\n",
    "\n",
    "# # Final aggregation across all days, summing up 'fishing_hours' for each bin\n",
    "# aggregated_data = aggregated_data.groupby(['lat_bin', 'lon_bin']).sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = os.path.join(os.getcwd(),os.pardir,os.pardir,'data','fishing_activity')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "save_file = os.path.join(save_folder,'fishing_activity_' + str(year) + '.csv')\n",
    "aggregated_data.to_csv(save_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
