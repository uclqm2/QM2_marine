{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = os.path.join(os.getcwd(),os.pardir,os.pardir,'data')\n",
    "data_list = os.listdir(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2012\n",
    "filename = 'mmsi-daily-csvs-10-v2-' + str(year)\n",
    "fishing_data_path = os.path.join(path_data,filename)\n",
    "# encoding='ISO-8859-1' for read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the bin size for latitude and longitude\n",
    "lat_bin_size = 5\n",
    "lon_bin_size = 5\n",
    "\n",
    "def calculate_bin(value, bin_size):\n",
    "    bin_center = ((value + bin_size/2) // bin_size) * bin_size\n",
    "    return bin_center\n",
    "\n",
    "start_date = datetime(year, 1, 1)\n",
    "end_date = datetime(year, 12, 31)\n",
    "delta = timedelta(days=1)\n",
    "\n",
    "lat_min, lat_max = -80, 80\n",
    "lon_min, lon_max = -180, 180\n",
    "\n",
    "lat_bins = np.arange(lat_min, lat_max + lat_bin_size, lat_bin_size)\n",
    "lon_bins = np.arange(lon_min, lon_max + lon_bin_size, lon_bin_size)\n",
    "\n",
    "# Initialize the aggregated data\n",
    "aggregated_data = pd.DataFrame()\n",
    "\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "    file_name = current_date.strftime('%Y-%m-%d') + '.csv'\n",
    "    file_path = os.path.join(fishing_data_path, file_name)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        daily_data = pd.read_csv(file_path)\n",
    "        daily_data = daily_data[['cell_ll_lat', 'cell_ll_lon', 'fishing_hours']]\n",
    "        daily_data = daily_data[daily_data['fishing_hours'] > 0]\n",
    "\n",
    "    daily_data['lat_bin'] = pd.cut(daily_data['cell_ll_lat'], bins = lat_bins)\n",
    "    daily_data['lon_bin'] = pd.cut(daily_data['cell_ll_lon'], bins = lon_bins)\n",
    "    daily_grouped = daily_data.groupby(['lat_bin', 'lon_bin']).agg({'fishing_hours': 'mean'}).reset_index()\n",
    "\n",
    "    aggregated_data = pd.concat([aggregated_data, daily_grouped])\n",
    "    current_date += delta\n",
    "\n",
    "# Final aggregation across all days, summing up 'fishing_hours' for each bin\n",
    "aggregated_data = aggregated_data.groupby(['lat_bin', 'lon_bin']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from datetime import datetime, timedelta\n",
    "\n",
    "# # Define the bin size for latitude and longitude\n",
    "# lat_bin_size = 5\n",
    "# lon_bin_size = 5\n",
    "\n",
    "# def calculate_bin(value, bin_size):\n",
    "#     bin_center = ((value + bin_size/2) // bin_size) * bin_size\n",
    "#     return bin_center\n",
    "\n",
    "# start_date = datetime(year, 1, 1)\n",
    "# end_date = datetime(year, 12, 31)\n",
    "# delta = timedelta(days=1)\n",
    "\n",
    "# # Initialize the aggregated data\n",
    "# aggregated_data = pd.DataFrame()\n",
    "\n",
    "# current_date = start_date\n",
    "# while current_date <= end_date:\n",
    "#     file_name = current_date.strftime('%Y-%m-%d') + '.csv'\n",
    "#     file_path = os.path.join(fishing_data_path, file_name)\n",
    "    \n",
    "#     if os.path.exists(file_path):\n",
    "#         daily_data = pd.read_csv(file_path)\n",
    "#         daily_data = daily_data[['cell_ll_lat', 'cell_ll_lon', 'fishing_hours']]\n",
    "#         daily_data = daily_data[daily_data['fishing_hours'] > 0]\n",
    "\n",
    "#     daily_data['lat_bin'] = daily_data['cell_ll_lat'].apply(calculate_bin, bin_size=lat_bin_size)\n",
    "#     daily_data['lon_bin'] = daily_data['cell_ll_lon'].apply(calculate_bin, bin_size=lon_bin_size)\n",
    "    \n",
    "#     # Group by the binned lat/lon and sum the 'fishing_hours', then compute the mean\n",
    "#     daily_grouped = daily_data.groupby(['lat_bin', 'lon_bin']).agg({'fishing_hours': 'mean'}).reset_index()\n",
    "    \n",
    "#     # Concatenate the grouped data to the aggregated data\n",
    "#     aggregated_data = pd.concat([aggregated_data, daily_grouped])\n",
    "    \n",
    "#     # Increment the date by one day\n",
    "#     current_date += delta\n",
    "\n",
    "# # Final aggregation across all days, summing up 'fishing_hours' for each bin\n",
    "# aggregated_data = aggregated_data.groupby(['lat_bin', 'lon_bin']).sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = os.path.join(os.getcwd(),os.pardir,os.pardir,'data','bin_fishing_activity')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "save_file = os.path.join(save_folder,'bin_fishing_activity_' + str(year) + '.csv')\n",
    "aggregated_data.to_csv(save_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
